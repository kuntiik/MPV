{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](wide-baseline-stereo-demo_files/att_00000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive image matching pipeline\n",
    "\n",
    "This is a helper jupyter notebook, which contains [interactive widgets](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Basics.html) for qualitative evaluation of the image matching pipeline and better understanding of the robust model fitting with RANSAC. You can plug-in the functions, which you have implemented, or use the pre-defined wrappers around OpenCV or kornia functions.\n",
    "\n",
    "It also can be useful as a template for writing your own visualizations or interactive apps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first do in in OpenCV to get the high-level understanding of the steps. We have two image as an input and would like to get corresponces and perspective transform between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended way of using this notebook\n",
    "\n",
    "This notebook is a helper tool for you to check if the modules you have developed are working in practice. For doing this, you select the appropriate function in the interactive section below. It would not be shown, until you run all the cells, as the interactive widgets are not persistent.\n",
    "\n",
    "You can also find and modify if you want, the commented implementation of the interactive part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import norm, uniform\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Button, HBox, VBox, Layout\n",
    "import ipywidgets as wd\n",
    "from IPython.display import YouTubeVideo\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from kornia_moons.feature import *\n",
    "import os\n",
    "DBL_EPS = np.finfo(float).eps\n",
    "\n",
    "#major, minor, *_ = [int(v) for v in cv2.__version__.split('.')]\n",
    "#assert major >= 4 and minor >= 5, f\"Please update your cv2. Required >= 4.5.0, yours: {cv2.__version__}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- jupyter notebook only START ---------------------\n",
    "if Path().absolute().name == \"RANSAC\":\n",
    "    os.chdir(str(Path().absolute().parent))\n",
    "\n",
    "from RANSAC.plot_planar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def timg_load(filename):\n",
    "    \"\"\" load an image, return a tensor image. \"\"\"\n",
    "    img = cv2.imread(filename)\n",
    "    with torch.no_grad():\n",
    "        timg = K.image_to_tensor(img, False).float() / 255\n",
    "        timg = K.color.bgr_to_grayscale(timg)\n",
    "    return timg\n",
    "\n",
    "def img_to_timg(timg):\n",
    "    timg = K.image_to_tensor(img1, False).float()/255.\n",
    "    if timg.shape[-3] == 3:\n",
    "        timg = K.color.rgb_to_grayscale(timg)\n",
    "    return timg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = {}\n",
    "rr['name'] = \"sdsd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sdsd'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detections = namedtuple('Detections', ['kps1',\n",
    "                                       'kps2',\n",
    "                                       'tentative_matches',\n",
    "                                       'pts_matches',\n",
    "                                       'H',\n",
    "                                       'inlier_mask',\n",
    "                                       'lafs1',\n",
    "                                       'lafs2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECT, ORIENT, AFFINE, DESCRIBE, MATCH, RANSAC\n",
    "\n",
    "### OUR PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "class CustomLocalFeatureMatcher():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def detectAndMatch(self,\n",
    "                       timg1: torch.Tensor,\n",
    "                       timg2: torch.Tensor,\n",
    "                       detector: str = 'kornia Harris',\n",
    "                       orientation: str = 'kornia orientation',\n",
    "                       affine: str = 'none',\n",
    "                       descriptor: str = 'kornia SIFT',\n",
    "                       match: str = 'kornia snn',\n",
    "                       ransac: str = 'kornia RANSAC') -> Detections:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "        ### Detector\n",
    "        if detector == 'kornia Harris':\n",
    "            detector = KF.ScaleSpaceDetector(2000,\n",
    "                              resp_module=KF.CornerGFTT(),\n",
    "                              nms_module=K.geometry.subpix.ConvQuadInterp3d(10, 1e-5),\n",
    "                              scale_pyr_module=K.geometry.ScalePyramid(3, 1.6, 32, double_image=False),\n",
    "                              ori_module=KF.PassLAF(),\n",
    "                              aff_module=KF.PassLAF(),\n",
    "                              mr_size=6.0).to(device)\n",
    "            lafs1, resps1 = detector(timg1, None)\n",
    "            lafs2, resps2 = detector(timg2, None)\n",
    "        elif detector == 'kornia Hessian':\n",
    "            detector = KF.ScaleSpaceDetector(2000,\n",
    "                              resp_module=KF.BlobHessian(),\n",
    "                              nms_module=K.geometry.subpix.ConvQuadInterp3d(10, 1e-5),\n",
    "                              scale_pyr_module=K.geometry.ScalePyramid(3, 1.6, 32, double_image=False),\n",
    "                              ori_module=KF.PassLAF(),\n",
    "                              aff_module=KF.PassLAF(),\n",
    "                              mr_size=6.0).to(device)\n",
    "            lafs1, resps1 = detector(timg1, None)\n",
    "            lafs2, resps2 = detector(timg2, None) \n",
    "        elif detector == 'assignment Hessian':\n",
    "            from local_detector import scalespace_hessian\n",
    "            # The threshold used here are for the reference implementation.\n",
    "            # Please, adjust them for your implementation\n",
    "            out1 = scalespace_hessian(timg1, 0.0001, 10, 1.3)\n",
    "            mrSize = 5.0\n",
    "            num_kpts = len(out1)\n",
    "            lafs1 = KF.laf_from_center_scale_ori(out1[:, 3:].reshape(1, -1, 2).flip(2),\n",
    "                                                 mrSize * out1[:, 2:3].reshape(1, -1, 1, 1),\n",
    "                                                 torch.zeros(1, num_kpts, 1))\n",
    "            \n",
    "            # The threshold used here are for the reference implementation.\n",
    "            # Please, adjust them for your implementation\n",
    "            out2 = scalespace_hessian(timg2, 0.0001, 10, 1.3)\n",
    "            num_kpts2 = len(out2)\n",
    "            lafs2 = KF.laf_from_center_scale_ori(out2[:, 3:].reshape(1, -1, 2).flip(2),\n",
    "                                                 mrSize * out2[:, 2:3].reshape(1, -1, 1, 1),\n",
    "                                                 torch.zeros(1, num_kpts2, 1))\n",
    "        elif detector == 'assignment Harris':\n",
    "            from local_detector import scalespace_harris\n",
    "            # The threshold used here are for the reference implementation.\n",
    "            # Please, adjust them for your implementation\n",
    "            mrSize = 5.0\n",
    "            \n",
    "            out1 = scalespace_harris(timg1, 0.000001, 10, 1.3)\n",
    "            num_kpts = len(out1)\n",
    "            lafs1 = KF.laf_from_center_scale_ori(out1[:, 3:].reshape(1, -1, 2).flip(2),\n",
    "                                                 mrSize *out1[:, 2:3].reshape(1, -1, 1, 1),\n",
    "                                                 torch.zeros(1, num_kpts, 1))\n",
    "            \n",
    "            # The threshold used here are for the reference implementation.\n",
    "            # Please, adjust them for your implementation\n",
    "            out2 = scalespace_harris(timg2, 0.000001, 10, 1.3)\n",
    "            num_kpts2 = len(out2)\n",
    "            lafs2 = KF.laf_from_center_scale_ori(out2[:, 3:].reshape(1, -1, 2).flip(2),\n",
    "                                                 mrSize * out2[:, 2:3].reshape(1, -1, 1, 1),\n",
    "                                                 torch.zeros(1, num_kpts2, 1))\n",
    "        else:\n",
    "            raise ValueError (\"Unknown detector\")\n",
    "\n",
    "        ### Optional affine shape estimation\n",
    "        \n",
    "        if affine == 'kornia affine':\n",
    "            aff = KF.LAFAffineShapeEstimator(19)\n",
    "            lafs1 = aff(lafs1, timg1)\n",
    "            lafs2 = aff(lafs2, timg2)\n",
    "        elif affine == 'assignment affine':\n",
    "            from local_descriptor import estimate_patch_affine_shape\n",
    "            def custom_aff(x):\n",
    "                return estimate_patch_affine_shape(x).unsqueeze(1)\n",
    "            aff = KF.LAFAffineShapeEstimator(19, affine_shape_detector=custom_aff)\n",
    "            lafs1 = aff(lafs1, timg1)\n",
    "            lafs2 = aff(lafs2, timg2)\n",
    "        elif affine == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError (\"Unknown orientation\")\n",
    "\n",
    "        ### Orientation estimation\n",
    "             \n",
    "        if orientation == 'kornia orientation':\n",
    "            ori = KF.LAFOrienter(19, 36)\n",
    "            lafs1 = ori(lafs1, timg1)\n",
    "            lafs2 = ori(lafs2, timg2)\n",
    "        elif orientation == 'assignment orientation':\n",
    "            from local_descriptor import estimate_patch_dominant_orientation\n",
    "            ori = KF.LAFOrienter(19, angle_detector=estimate_patch_dominant_orientation)\n",
    "            lafs1 = ori(lafs1, timg1)\n",
    "            lafs2 = ori(lafs2, timg2)\n",
    "        elif orientation == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError (\"Unknown orientation\")\n",
    "\n",
    "        ### Descriptor\n",
    "        if descriptor == 'kornia SIFT':\n",
    "            desc_module = KF.LAFDescriptor(KF.SIFTDescriptor(32, rootsift=True), 32)\n",
    "            \n",
    "            desc1 = desc_module(timg1, lafs1).reshape(lafs1.shape[1], -1)\n",
    "            desc2 = desc_module(timg2, lafs2).reshape(lafs2.shape[1], -1)\n",
    "        elif descriptor == 'assignment SIFT':\n",
    "            from local_descriptor import calc_sift_descriptor\n",
    "            class TempDesc(nn.Module):\n",
    "                def forward(self, x):\n",
    "                    return calc_sift_descriptor(x)\n",
    "            desc_module = KF.LAFDescriptor(TempDesc(), 32)\n",
    "            desc1 = desc_module(timg1, lafs1).reshape(lafs1.shape[1], -1)\n",
    "            desc2 = desc_module(timg2, lafs2).reshape(lafs2.shape[1], -1)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown descriptor\")\n",
    "        \n",
    "        ### Matching \n",
    "        if match == 'kornia snn':\n",
    "            dists, idxs = KF.match_snn(desc1, desc2, 0.9)\n",
    "        elif match == 'assignment snn':\n",
    "            from matching import match_snn\n",
    "            dists, idxs = match_snn(desc1, desc2, 0.9)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown matching\")\n",
    "        \n",
    "        pts_matches1 = KF.get_laf_center(lafs1[:, idxs[:, 0]]).view(-1, 2)\n",
    "        pts_matches2 = KF.get_laf_center(lafs2[:, idxs[:, 1]]).view(-1, 2)\n",
    "        \n",
    "        if ransac == 'kornia RANSAC':\n",
    "            RANSAC =  K.geometry.RANSAC('homography', 5.0, 1024, 5)\n",
    "            H, inliers_mask = RANSAC(pts_matches1, pts_matches2)\n",
    "        elif ransac == 'assignment RANSAC':\n",
    "            from ransac import ransac_h\n",
    "            H, inliers_mask = ransac_h(torch.cat([pts_matches1, pts_matches2], dim=1))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown RANSAC\")\n",
    "            \n",
    "        kps1 = KF.get_laf_center(lafs1).view(-1, 2)\n",
    "        kps2 = KF.get_laf_center(lafs2).view(-1, 2)\n",
    "        \n",
    "        result = Detections(kps1,\n",
    "                            kps2,\n",
    "                            idxs,\n",
    "                            torch.cat([pts_matches1, pts_matches2],dim=1),\n",
    "                            H,\n",
    "                            inliers_mask,\n",
    "                            lafs1,\n",
    "                            lafs2)\n",
    "        \n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will load a couple of images to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg1 = timg_load('v_woman1.ppm')\n",
    "timg2 = timg_load('v_woman6.ppm')\n",
    "\n",
    "img1 = K.tensor_to_image(255*timg1).astype(np.uint8)\n",
    "img2 = K.tensor_to_image(255*timg2).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the choices for the drop-down list. They should match whatever we have inside `CustomLocalFeatureMatcher` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_detectors = [\"kornia Harris\",\n",
    "                      \"kornia Hessian\",\n",
    "                      \"assignment Harris\",\n",
    "                      \"assignment Hessian\"]\n",
    "possible_ori = [\"none\",\n",
    "                \"kornia orientation\",\n",
    "                \"assignment orientation\"]\n",
    "\n",
    "possible_affine = [\"none\",\n",
    "                   \"kornia affine\",\n",
    "                   \"assignment affine\"]\n",
    "\n",
    "possible_descriptor = [\"kornia SIFT\",\n",
    "                       \"assignment SIFT\"]\n",
    "\n",
    "possible_matching = [\"kornia snn\",\n",
    "                     \"assignment snn\"]\n",
    "\n",
    "possible_ransac = [\"kornia RANSAC\",\n",
    "                   \"assignment RANSAC\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETRIZATION\n",
    "\n",
    "Throughout the whole notebook, we use data classes to parametrize algorithms. They are easy to use. They are extensible and clean. We encourage you to add new parameters and adjust our code to your needs. You can change the detection, description, and matching pipeline completely or use our and tweak the parameters.\n",
    "\n",
    "## Dataclasses\n",
    "\n",
    "We defined multiple data classes RansacPlanarFunctions, RansacPlanarParams, and PlotParams. We use them for storing values and parametrization. Their advantage over simple dictionaries is that they have defined values, are comparable, and [many others](https://docs.python.org/3/library/dataclasses.html). We also use them to store RANSAC output.\n",
    "\n",
    "Below, you can see how do we define them within the hidden codebase. You can change all of the values below in the initialization section. (or during runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are default parameters for out app.\n",
    "@dataclass(eq=False)\n",
    "class WxBSParams:\n",
    "    detector: str = 'kornia Harris'\n",
    "    orientation: str = 'kornia orientation'\n",
    "    affine: str = 'none'\n",
    "    descriptor: str = 'kornia SIFT'\n",
    "    match: str = 'kornia snn'\n",
    "    ransac: str = 'kornia RANSAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_params = WxBSParams()\n",
    "plt_params = PlotParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and support plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes in which inliers/outliers are displayed.\n",
    "# Modes works as follows: there are three modes: 0, 1, 2.\n",
    "#                         Mode 0: do not plot anything\n",
    "#                         Mode 1: show only keypoints (in both images)\n",
    "#                         Mode 2: show regions (in both images)\n",
    "#                         Mode 3: show keypoints and connect them with lines\n",
    "#                         Mode 4: show regions and connect them with lines\n",
    "\n",
    "visualization_options = {\n",
    "    \"inliers_display_mode\": 4,\n",
    "    \"outliers_display_mode\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "# buttons that control the run of the algorithm\n",
    "alg_buttons = [\n",
    "    wd.Button(description=\"detect\"),\n",
    "    wd.Button(description=\"match\"),\n",
    "\n",
    "]\n",
    "\n",
    "det_selector = wd.Dropdown(description='Detector',\n",
    "                           options=possible_detectors,\n",
    "                           value=possible_detectors[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "\n",
    "ori_selector = wd.Dropdown(description='Orientation',\n",
    "                           options=possible_ori,\n",
    "                           value=possible_ori[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "\n",
    "affine_selector = wd.Dropdown(description='Affine',\n",
    "                           options=possible_affine,\n",
    "                           value=possible_affine[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "\n",
    "\n",
    "descriptor_selector = wd.Dropdown(description='Descriptor',\n",
    "                           options=possible_descriptor,\n",
    "                           value=possible_descriptor[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "matching_selector = wd.Dropdown(description='Matching',\n",
    "                           options=possible_matching,\n",
    "                           value=possible_matching[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "\n",
    "ransac_selector = wd.Dropdown(description='RANSAC',\n",
    "                           options=possible_ransac,\n",
    "                           value=possible_ransac[0],\n",
    "                           layout=Layout(width='80%'))\n",
    "\n",
    "# buttons that control the visualizations\n",
    "visu_buttons = [\n",
    "    wd.Button(description=f\"inl display mode: {visualization_options['inliers_display_mode']}\"),\n",
    "    wd.Button(description=f\"out display mode: {visualization_options['outliers_display_mode']}\"),\n",
    "]\n",
    "\n",
    "dropdowns = [\n",
    "    det_selector,\n",
    "    ori_selector,\n",
    "    affine_selector,\n",
    "    descriptor_selector, \n",
    "    matching_selector,\n",
    "    ransac_selector]\n",
    "\n",
    "def disable_buttons(func: Callable):\n",
    "    \"\"\" Decorator that disables all buttons during the run of the function func \"\"\"\n",
    "    def disable_enable(*args, **kwargs):\n",
    "        global visu_buttons, alg_buttons\n",
    "        buttons = visu_buttons + alg_buttons\n",
    "        for btn in buttons:\n",
    "            btn.disabled = True\n",
    "        result = func(*args, **kwargs)\n",
    "        for btn in buttons:\n",
    "            btn.disabled = False\n",
    "        return result\n",
    "    return disable_enable\n",
    "\n",
    "\n",
    "def output_img_update(img):\n",
    "    \"\"\" Update the output_img. Display the image img.\"\"\"\n",
    "    with output_img:\n",
    "        output_img.clear_output(True)\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def show_keypoints():\n",
    "    \"\"\" Show only keypoints.\"\"\"\n",
    "    global img1, img2, detections, plt_params\n",
    "    img = draw_keypoints(img1, img2, detections.lafs1, detections.lafs2, plt_params)\n",
    "    output_img_update(img)\n",
    "\n",
    "\n",
    "@disable_buttons\n",
    "def reset_H_keypoints_show(_=None):\n",
    "    \"\"\" \n",
    "    Reset both current and the best RANSAC run. \n",
    "    Forget all homographies, inliers, outliers, etc., and show only keypoints.\n",
    "    \"\"\"\n",
    "    global detections, img1, img2, plt_params, timg1, timg2, params, functions, log, best_log\n",
    "    log = RansacPlanarLog()\n",
    "    best_log = RansacPlanarLog()\n",
    "    show_keypoints()\n",
    "    with output_legend:\n",
    "        output_legend.clear_output(True)\n",
    "        output_best_legend.clear_output(True)\n",
    "        plot_legend_init(detections.kps1, detections.kps2, plt_params)\n",
    "\n",
    "\n",
    "@disable_buttons\n",
    "def run_detector_show(_=None):\n",
    "    \"\"\" Reset all RANSAC runs and run the detect/describe/match pipeline. \"\"\"\n",
    "    global detections, img1, img2, plt_params, timg1, timg2, params, functions, matching_params\n",
    "    cfm = CustomLocalFeatureMatcher()\n",
    "    with torch.no_grad():\n",
    "        detections = cfm.detectAndMatch(timg1, timg2,\n",
    "                                 det_selector.value,\n",
    "                                 ori_selector.value,\n",
    "                                 affine_selector.value,\n",
    "                                 descriptor_selector.value,\n",
    "                                 matching_selector.value,\n",
    "                                 ransac_selector.value)\n",
    "    reset_H_keypoints_show()\n",
    "\n",
    "\n",
    "def output_legend_update(_=None):\n",
    "    \"\"\" Update both current output legend and the best output legend \"\"\"\n",
    "    global log, best_log, detections, plt_params, output_legend, output_best_legend\n",
    "    with output_legend:\n",
    "        output_legend.clear_output(True)\n",
    "        plot_current_legend(log, detections, plt_params)\n",
    "\n",
    "\n",
    "def show_matches():\n",
    "    \"\"\" Show current inliers, outliers, homography, update legends etc. \"\"\"\n",
    "    global img1, img2, detections, log, plt_params, best_log\n",
    "    img = draw_matches(img1, img2, detections, plt_params, visualization_options)\n",
    "    output_img_update(img)\n",
    "    output_legend_update()\n",
    "\n",
    "    \n",
    "def inliers_display_mode(_=None):\n",
    "    \"\"\" Cycle the inliers display mode \"\"\"\n",
    "    global visualization_options, log, best_log, visu_buttons\n",
    "    visualization_options[\"inliers_display_mode\"] = (visualization_options[\"inliers_display_mode\"]+1)%4\n",
    "    visu_buttons[0].description = f\"inl display mode: {visualization_options['inliers_display_mode']}\"\n",
    "    if detections.H is None:\n",
    "        show_keypoints()\n",
    "    else:\n",
    "        show_matches()\n",
    "\n",
    "    \n",
    "def outliers_display_mode(_=None):\n",
    "    \"\"\" Cycle the outliers display mode \"\"\"\n",
    "    global visualization_options, log, best_log, visu_buttons\n",
    "    visualization_options[\"outliers_display_mode\"] = (visualization_options[\"outliers_display_mode\"]+1)%4\n",
    "    visu_buttons[1].description =f\"out display mode: {visualization_options['outliers_display_mode']}\"\n",
    "    if detections.H is None:\n",
    "        show_keypoints()\n",
    "    else:\n",
    "        show_matches()\n",
    "\n",
    "\n",
    "\n",
    "@disable_buttons\n",
    "def ransac_fit_show(_=None):\n",
    "    \"\"\" Run the complete RANSAC algorithm, and show the result. \"\"\"\n",
    "    global detections, plt_params, params, functions, log, img1, img2, best_log\n",
    "    #update_params()\n",
    "    with torch.no_grad():\n",
    "        cfm = CustomLocalFeatureMatcher()\n",
    "        detections = cfm.detectAndMatch(timg1, timg2,\n",
    "                                 det_selector.value,\n",
    "                                 ori_selector.value,\n",
    "                                 affine_selector.value,\n",
    "                                 descriptor_selector.value,\n",
    "                                 matching_selector.value,\n",
    "                                 ransac_selector.value)\n",
    "    show_matches()\n",
    "\n",
    "\n",
    "@disable_buttons\n",
    "def switch_images_show(_=None):\n",
    "    \"\"\" Forget the current configuration and swap images. \"\"\"\n",
    "    global img1, img2, timg1, timg2, detections\n",
    "    timg1, timg2 = timg2, timg1\n",
    "    img1, img2 = img2, img1\n",
    "    old_d = detections\n",
    "    detections = Detections(detections.kps2,\n",
    "                            detections.kps1,\n",
    "                            detections.tentative_matches,\n",
    "                            detections.pts_matches,\n",
    "                             detections.H,\n",
    "                             detections.inlier_mask,\n",
    "                            detections.lafs1,\n",
    "                            detections.lafs2)\n",
    "    reset_H_keypoints_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_buttons[0].on_click(run_detector_show)\n",
    "alg_buttons[1].on_click(ransac_fit_show)\n",
    "visu_buttons[0].on_click(inliers_display_mode)\n",
    "visu_buttons[1].on_click(outliers_display_mode)\n",
    "\n",
    "\n",
    "layout_space = Layout(display=\"flex\", justify_content=\"space-between\")\n",
    "\n",
    "output_img = wd.Output()\n",
    "output_legend = wd.Output()\n",
    "output_best_legend = wd.Output()\n",
    "hb_control_panel = HBox([output_legend,\n",
    "                         output_best_legend, \n",
    "                         VBox(visu_buttons), VBox(alg_buttons), VBox(dropdowns)], \n",
    "                        layout=layout_space)\n",
    "app = VBox([hb_control_panel, output_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/python39/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f36938936e44db59cf6827d573b8daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Output(), Output(), VBox(children=(Button(description='inl display mode: 4', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_detector_show()\n",
    "display(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
